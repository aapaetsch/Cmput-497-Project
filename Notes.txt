- Summarize highs and lows 
	- Issue with the evaluation function
		- Speed (was too slow evaluating each state line by line)
			- Solved by precalculating scores for each possible line and just accessing those scores for the evaluation
			- these are generated by eval.py and found in scores.json
		- Computer was not blocking opponents moves, just would do moves that would increase its own score
			- multiplying the opponents score by X1.5, this causes blocking to be worth more than creating runs of our own

	- Highs:
		- bringing concepts together from multiple classes 
			- alpha beta search (Depth limited)
			- Transposition tables
			- zobrist hashing
		- learning more about the game (four in a row)
			- more complex than originally thought
			- many more states than anticipated 

- Goals: 
	- Yes, working Four in a row program that also can play itself 
		- (Usually) the higher difficulties win 


- Continuation:
	- Create a GUI ? 
	- A better looking way to show the history/ computer decisions
	- Faster implementation of the game & evaluation functions 
		- This would allow our program to search even greater depths in a reasonable amount of time

- 3 options
	- pvp 
	- pvc 
	- cvc

	- pvc You can choose if the computer or player goes first
	- can choose difficulty of the cpu 
		- easy = d1
		- medium = d5
		- hard = d9 

- Game is run by FourInARowText.py

- fourInARow.py
	-game board, checking winning states, checking legal moves (essential game functions) 
	- show board

- eval.py
	- evaluation functions. 
		- we pre calculate all of the scores for each row so that they can be accessed by the computer players evaluation function

- scores.json
	- holds the scores calculated using eval.py

- Computer_Player.py
	- We use Depth limited Alpha beta search
		- This allows for us to stop searching at whatever depth we desire

	- Transposition table
		- dictionary[Hashvalue: score]
		- hash values are calculated using 128 bit zobrist hashing
			- we store the current hash value
			- This allows us to update the hash value for every move that we simulate
			- this way we only have to increment the hash value instead of recalculating the entire board
		- Turns the search tree into a DAG - directed acyclic graph
			- We recognize and store/retrieve the scores for states we have already visited

	- History Heuristic : USED TO ORDER LEGAL MOVES
		- Causes a significant speed increase for search depths up to 8
		- see link on fb 
		- += 2^D for the weight 
		- update the heuristic whenever we find a move results in a beta cut 
